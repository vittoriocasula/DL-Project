{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "print(os.getcwd())\n",
    "os.chdir(\"../../\")\n",
    "os.getcwd()\n",
    "\n",
    "sys.argv = [\"view\", \"--config\", \"config/multi_task_cross_stitch.yaml\"]\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--config\", type=str, required=True, help=\"Path to the config file\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(args.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments import config\n",
    "from utils import set_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = set_device(config[\"global\"][\"gpu_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import AlexNet_Weights, VGG16_Weights\n",
    "from config_experiments import config\n",
    "from bbox_transform import regr_to_bbox\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import wandb\n",
    "\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Backbone, self).__init__()\n",
    "        # rawnet = torchvision.models.alexnet(weights=AlexNet_Weights.DEFAULT)\n",
    "        rawnet = torchvision.models.vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "\n",
    "        self.features = nn.Sequential(*list(rawnet.features.children())[:-1])\n",
    "\n",
    "        # Freezare il primo layer conv\n",
    "        self.features[0].weight.requires_grad = False\n",
    "        self.features[0].bias.requires_grad = False\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.features(input)\n",
    "\n",
    "\n",
    "class ROI_Module(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ROI_Module, self).__init__()\n",
    "\n",
    "        self.roipool = torchvision.ops.RoIPool(\n",
    "            output_size=(\n",
    "                config[\"model\"][\"output_size_roipool\"][0],\n",
    "                config[\"model\"][\"output_size_roipool\"][1],\n",
    "            ),\n",
    "            spatial_scale=config[\"model\"][\"spatial_scale\"],\n",
    "        )\n",
    "\n",
    "    def forward(self, features, rois, ridx):\n",
    "        idx_rois = torch.cat(\n",
    "            (ridx, rois), dim=-1\n",
    "        )  # create matrix with (batch_idx, rois(xyxy))\n",
    "        res = self.roipool(features, idx_rois)\n",
    "        res = res.view(res.size(0), -1)\n",
    "        return res\n",
    "\n",
    "\n",
    "class CrossStitchClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CrossStitchClassifier, self).__init__()\n",
    "\n",
    "        self.branch_a = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(\n",
    "                512  # 256\n",
    "                * config[\"model\"][\"output_size_roipool\"][0]\n",
    "                * config[\"model\"][\"output_size_roipool\"][1],\n",
    "                4096,\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.branch_b = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(\n",
    "                512  # 256\n",
    "                * config[\"model\"][\"output_size_roipool\"][0]\n",
    "                * config[\"model\"][\"output_size_roipool\"][1],\n",
    "                4096,\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.cross_stitch_1 = CrossStitchUnit()\n",
    "        self.cross_stitch_2 = CrossStitchUnit()\n",
    "\n",
    "    def forward(self, x_a, x_b):\n",
    "\n",
    "        x_a = self.branch_a[0:4](x_a)\n",
    "        x_b = self.branch_b[0:4](x_b)\n",
    "        x_a, x_b = self.cross_stitch_1(x_a, x_b)\n",
    "        x_a = self.branch_a[4:](x_a)\n",
    "        x_b = self.branch_b[4:](x_b)\n",
    "        x_a, x_b = self.cross_stitch_2(x_a, x_b)\n",
    "        return x_a, x_b\n",
    "\n",
    "\n",
    "class AttributePredictionHead(nn.Module):\n",
    "    def __init__(self, num_attributes=config[\"global\"][\"num_attributes\"]):\n",
    "        super().__init__()\n",
    "        self.num_attributes = num_attributes\n",
    "\n",
    "        self.attr_score = nn.Linear(4096, self.num_attributes)\n",
    "        nn.init.normal_(self.attr_score.weight, mean=0, std=0.01)\n",
    "        nn.init.constant_(self.attr_score.bias, 0)\n",
    "\n",
    "    def forward(self, feat):\n",
    "        attr_score = self.attr_score(feat)\n",
    "        return attr_score\n",
    "\n",
    "\n",
    "class AttributePredictionModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.alex = Backbone()\n",
    "        self.roi_module = ROI_Module()\n",
    "        self.attribute_head = AttributePredictionHead(\n",
    "            num_attributes=config[\"global\"][\"num_attributes\"]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, rois, ridx):\n",
    "        out = self.alex(x)\n",
    "        out = self.roi_module(out, rois, ridx)\n",
    "        score_attr = self.attribute_head(out)\n",
    "        return score_attr\n",
    "\n",
    "    def prediction_rois(self, img, rois, ridx):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            sc_attr = self(img, rois, ridx)\n",
    "        score_attr = nn.functional.sigmoid(sc_attr)\n",
    "        attr = torch.where(sc_attr > 0.5, torch.tensor(1.0), torch.tensor(0.0))\n",
    "        return attr, score_attr\n",
    "\n",
    "    def calc_loss(\n",
    "        self,\n",
    "        attr,\n",
    "        labels,\n",
    "        gt_attr,\n",
    "    ):\n",
    "\n",
    "        bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        if (\n",
    "            len(attr[labels != 0]) == 0 or len(gt_attr[labels != 0]) == 0\n",
    "        ):  # gestisci il caso in cui non c'è bbox positivi\n",
    "            loss_attr = torch.tensor(0.0, requires_grad=True).to(labels.device)\n",
    "        else:\n",
    "            loss_attr = bce(attr[labels != 0], gt_attr[labels != 0])\n",
    "        return loss_attr\n",
    "\n",
    "\n",
    "class ObjectDetectionHead(nn.Module):\n",
    "    def __init__(self, num_classes=config[\"global\"][\"num_classes\"]):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.cls_score = nn.Linear(4096, self.num_classes + 1)\n",
    "        self.bbox = nn.Linear(4096, 4 * (self.num_classes + 1))\n",
    "\n",
    "        nn.init.normal_(self.cls_score.weight, mean=0, std=0.01)\n",
    "        nn.init.normal_(self.bbox.weight, mean=0, std=0.001)\n",
    "\n",
    "        nn.init.constant_(self.cls_score.bias, 0)\n",
    "        nn.init.constant_(self.bbox.bias, 0)\n",
    "\n",
    "    def forward(self, feat):\n",
    "        cls_score = self.cls_score(feat)\n",
    "        bbox = self.bbox(feat).view(-1, self.num_classes + 1, 4)\n",
    "        return cls_score, bbox\n",
    "\n",
    "\n",
    "class ObjectDetectionModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.alex = Backbone()\n",
    "        self.roi_module = ROI_Module()\n",
    "        self.obj_detect_head = ObjectDetectionHead(\n",
    "            num_classes=config[\"global\"][\"num_classes\"]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, rois, ridx):\n",
    "        out = self.alex(x)\n",
    "        out = self.roi_module(out, rois, ridx)\n",
    "        cls_score, bbox = self.obj_detect_head(out)\n",
    "        return cls_score, bbox\n",
    "\n",
    "    def prediction_img(self, img, rois, ridx):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            score, tbbox = self(img, rois, ridx)\n",
    "        _, _, heigth, width = img.shape\n",
    "        score = nn.functional.softmax(score, dim=-1)\n",
    "        max_score, cls_max_score = torch.max(score, dim=-1)\n",
    "\n",
    "        bboxs = regr_to_bbox(rois, tbbox, (heigth, width))\n",
    "\n",
    "        bboxs = bboxs[torch.arange(cls_max_score.shape[0]), cls_max_score]\n",
    "        return cls_max_score, max_score, bboxs\n",
    "\n",
    "    def calc_loss(\n",
    "        self,\n",
    "        probs,\n",
    "        bbox,\n",
    "        labels,\n",
    "        gt_bbox,\n",
    "    ):\n",
    "\n",
    "        cel = nn.CrossEntropyLoss()\n",
    "\n",
    "        sl1 = nn.SmoothL1Loss(reduction=\"none\")\n",
    "        loss_sc = cel(probs, labels)\n",
    "\n",
    "        mask = (labels != 0).bool()\n",
    "        t_u = bbox[torch.arange(bbox.shape[0]), labels]\n",
    "        loss_loc = (\n",
    "            torch.sum(torch.sum(sl1(t_u[mask], gt_bbox[mask]), dim=1), dim=0)\n",
    "            / labels.shape[0]\n",
    "        )\n",
    "\n",
    "        loss_sc = config[\"loss\"][\"lmb_cls\"] * loss_sc\n",
    "        loss_loc = config[\"loss\"][\"lmb_loc\"] * loss_loc\n",
    "        loss = loss_sc + loss_loc\n",
    "        return loss, loss_sc, loss_loc\n",
    "\n",
    "\n",
    "class CrossStitchBackbone(\n",
    "    nn.Module\n",
    "):  # one cross-stitch units after every pooling layer\n",
    "    def __init__(self, vgg_a, vgg_b):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        self.models_a = nn.ModuleList(\n",
    "            [nn.Sequential(*alex_a[i:j]) for i, j in [(0, 3), (3, 6), (6, 12)]]\n",
    "        )\n",
    "        self.models_b = nn.ModuleList(\n",
    "            [nn.Sequential(*alex_b[i:j]) for i, j in [(0, 3), (3, 6), (6, 12)]]\n",
    "        )\n",
    "        self.cross_stitch_units = nn.ModuleList([CrossStitchUnit() for _ in range(3)])\n",
    "        \"\"\"\n",
    "\n",
    "        # Identify the layers in VGG where pooling occurs\n",
    "        # VGG-16 structure: conv -> relu -> conv -> relu -> pool (repeat 5 times)\n",
    "        self.models_a = nn.ModuleList(\n",
    "            [\n",
    "                nn.Sequential(*vgg_a[i:j])\n",
    "                for i, j in [(0, 5), (5, 10), (10, 17), (17, 24), (24, 30)]\n",
    "            ]\n",
    "        )\n",
    "        self.models_b = nn.ModuleList(\n",
    "            [\n",
    "                nn.Sequential(*vgg_b[i:j])\n",
    "                for i, j in [(0, 5), (5, 10), (10, 17), (17, 24), (24, 30)]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Create CrossStitchUnits for each pooling layer\n",
    "        self.cross_stitch_units = nn.ModuleList([CrossStitchUnit() for _ in range(5)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_a, out_b = x, x\n",
    "        for model_a, model_b, cross_stitch in zip(\n",
    "            self.models_a, self.models_b, self.cross_stitch_units\n",
    "        ):\n",
    "            out_a, out_b = model_a(out_a), model_b(out_b)\n",
    "            out_a, out_b = cross_stitch(out_a, out_b)\n",
    "        return out_a, out_b\n",
    "\n",
    "\n",
    "class CrossStitchUnit(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.alfa_a = nn.Parameter(\n",
    "            torch.tensor(config[\"cross_stitch\"][\"alfa_a_init\"], dtype=torch.float32),\n",
    "            requires_grad=True,\n",
    "        )\n",
    "        self.alfa_b = nn.Parameter(\n",
    "            torch.tensor(config[\"cross_stitch\"][\"alfa_b_init\"], dtype=torch.float32),\n",
    "            requires_grad=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, xa, xb):\n",
    "        new_xa = self.alfa_a[0] * xa + self.alfa_a[1] * xb\n",
    "        new_xb = self.alfa_b[0] * xa + self.alfa_b[1] * xb\n",
    "        return new_xa, new_xb\n",
    "\n",
    "    def log_parameters(self):\n",
    "        # Loggare i valori di alfa_a e alfa_b su wandb\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"alfa_a_0\": self.alfa_a[0].item(),\n",
    "                \"alfa_a_1\": self.alfa_a[1].item(),\n",
    "                \"alfa_b_0\": self.alfa_b[0].item(),\n",
    "                \"alfa_b_1\": self.alfa_b[1].item(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "class CrossStitchNet(nn.Module):\n",
    "    def __init__(self, alex_a, alex_b):\n",
    "        super().__init__()\n",
    "        if alex_a is None or alex_b is None:\n",
    "            alex_a = Backbone()\n",
    "            alex_b = Backbone()\n",
    "        self.cross_stitch_net = CrossStitchBackbone(alex_a.features, alex_b.features)\n",
    "        self.roi_a = ROI_Module()\n",
    "        self.roi_b = ROI_Module()\n",
    "\n",
    "        self.cross_stitch_classifier = CrossStitchClassifier()\n",
    "\n",
    "        self.model_obj_detect = ObjectDetectionHead(\n",
    "            num_classes=config[\"global\"][\"num_classes\"]\n",
    "        )\n",
    "        self.model_attribute = AttributePredictionHead(\n",
    "            num_attributes=config[\"global\"][\"num_attributes\"]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, rois, ridx):\n",
    "        out_a, out_b = self.cross_stitch_net(x)\n",
    "        out_a = self.roi_a(out_a, rois, ridx)\n",
    "        out_b = self.roi_b(out_b, rois, ridx)\n",
    "        out_a, out_b = self.cross_stitch_classifier(out_a, out_b)\n",
    "        cls_score, bbox = self.model_obj_detect(out_a)\n",
    "        attr_score = self.model_attribute(out_b)\n",
    "        return cls_score, bbox, attr_score  # cls_score, bbox, attr_score\n",
    "\n",
    "    def prediction_img(self, img, rois, ridx):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            score, tbbox, _ = self(img, rois, ridx)\n",
    "        _, _, heigth, width = img.shape\n",
    "        score = nn.functional.softmax(score, dim=-1)\n",
    "        max_score, cls_max_score = torch.max(score, dim=-1)\n",
    "\n",
    "        bboxs = regr_to_bbox(rois, tbbox, (heigth, width))\n",
    "\n",
    "        bboxs = bboxs[torch.arange(cls_max_score.shape[0]), cls_max_score]\n",
    "        # bboxs = self.unnormalize_bbox(bboxs)\n",
    "        return cls_max_score, max_score, bboxs\n",
    "\n",
    "    def prediction_rois(self, img, rois, ridx):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            _, _, sc_attr = self(img, rois, ridx)\n",
    "        score_attr = nn.functional.sigmoid(sc_attr)\n",
    "        attr = torch.where(\n",
    "            score_attr > 0.5,\n",
    "            torch.tensor(1.0, device=sc_attr.device),\n",
    "            torch.tensor(0.0, device=sc_attr.device),\n",
    "        )\n",
    "        return attr, score_attr\n",
    "\n",
    "    def calc_loss(\n",
    "        self,\n",
    "        probs,\n",
    "        bbox,\n",
    "        labels,\n",
    "        gt_bbox,\n",
    "        attr,\n",
    "        gt_attr,\n",
    "    ):\n",
    "\n",
    "        cel = nn.CrossEntropyLoss()\n",
    "        sl1 = nn.SmoothL1Loss(reduction=\"none\")\n",
    "        bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        loss_sc = cel(probs, labels)\n",
    "\n",
    "        mask = (labels != 0).bool()\n",
    "        t_u = bbox[torch.arange(bbox.shape[0]), labels]\n",
    "        loss_loc = (\n",
    "            torch.sum(torch.sum(sl1(t_u[mask], gt_bbox[mask]), dim=1), dim=0)\n",
    "            / labels.shape[0]\n",
    "        )\n",
    "        if (\n",
    "            len(attr[labels != 0]) == 0 or len(gt_attr[labels != 0]) == 0\n",
    "        ):  # gestiscri il caso in cui non c'è bbox positivi\n",
    "            loss_attr = torch.tensor(0.0, requires_grad=True).to(labels.device)\n",
    "        else:\n",
    "            loss_attr = bce(attr[labels != 0], gt_attr[labels != 0])\n",
    "\n",
    "        loss_sc = config[\"loss\"][\"lmb_cls\"] * loss_sc\n",
    "        loss_loc = config[\"loss\"][\"lmb_loc\"] * loss_loc\n",
    "        loss_attr = config[\"loss\"][\"lmb_attr\"] * loss_attr\n",
    "\n",
    "        loss = loss_sc + loss_loc\n",
    "\n",
    "        loss = loss_sc + loss_loc + loss_attr  # METTI LA COSTANTE DAVANTI A LOSS_ATTR\n",
    "\n",
    "        return loss, loss_sc, loss_loc, loss_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CrossStitchNet(None, None)\n",
    "\n",
    "from dataloader import VOC08Attr\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_data = VOC08Attr(\n",
    "    train=True,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(\n",
    "                size=config[\"transform\"][\"resize_values\"],\n",
    "                max_size=config[\"transform\"][\"max_size\"],\n",
    "            ),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=config[\"transform\"][\"mean\"], std=config[\"transform\"][\"std\"]\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=config[\"preprocessing\"][\"n_images\"],\n",
    "    collate_fn=train_data.collate_fn,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "image, train_roi, train_cls, train_offset, train_attr, indices_batch = next(\n",
    "    iter(train_dataloader)\n",
    ")\n",
    "cls_score, bbox_offset, attr = model(image, train_roi, indices_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONLY AFTER MAX POOLING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import AlexNet_Weights, VGG16_Weights\n",
    "from config_experiments import config\n",
    "from bbox_transform import regr_to_bbox\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import wandb\n",
    "\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Backbone, self).__init__()\n",
    "        # rawnet = torchvision.models.alexnet(weights=AlexNet_Weights.DEFAULT)\n",
    "        rawnet = torchvision.models.vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "\n",
    "        self.features = nn.Sequential(*list(rawnet.features.children())[:-1])\n",
    "\n",
    "        # Freezare il primo layer conv\n",
    "        self.features[0].weight.requires_grad = False\n",
    "        self.features[0].bias.requires_grad = False\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.features(input)\n",
    "\n",
    "\n",
    "class ROI_Module(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ROI_Module, self).__init__()\n",
    "\n",
    "        self.roipool = torchvision.ops.RoIPool(\n",
    "            output_size=(\n",
    "                config[\"model\"][\"output_size_roipool\"][0],\n",
    "                config[\"model\"][\"output_size_roipool\"][1],\n",
    "            ),\n",
    "            spatial_scale=config[\"model\"][\"spatial_scale\"],\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(\n",
    "                512  # 256\n",
    "                * config[\"model\"][\"output_size_roipool\"][0]\n",
    "                * config[\"model\"][\"output_size_roipool\"][1],\n",
    "                4096,\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, features, rois, ridx):\n",
    "        idx_rois = torch.cat(\n",
    "            (ridx, rois), dim=-1\n",
    "        )  # create matrix with (batch_idx, rois(xyxy))\n",
    "        res = self.roipool(features, idx_rois)\n",
    "        res = res.view(res.size(0), -1)\n",
    "        feat = self.classifier(res)\n",
    "        return feat\n",
    "\n",
    "\n",
    "class AttributePredictionHead(nn.Module):\n",
    "    def __init__(self, num_attributes=config[\"global\"][\"num_attributes\"]):\n",
    "        super().__init__()\n",
    "        self.num_attributes = num_attributes\n",
    "\n",
    "        self.attr_score = nn.Linear(4096, self.num_attributes)\n",
    "        nn.init.normal_(self.attr_score.weight, mean=0, std=0.01)\n",
    "        nn.init.constant_(self.attr_score.bias, 0)\n",
    "\n",
    "    def forward(self, feat):\n",
    "        attr_score = self.attr_score(feat)\n",
    "        return attr_score\n",
    "\n",
    "\n",
    "class AttributePredictionModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.alex = Backbone()\n",
    "        self.roi_module = ROI_Module()\n",
    "        self.attribute_head = AttributePredictionHead(\n",
    "            num_attributes=config[\"global\"][\"num_attributes\"]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, rois, ridx):\n",
    "        out = self.alex(x)\n",
    "        out = self.roi_module(out, rois, ridx)\n",
    "        score_attr = self.attribute_head(out)\n",
    "        return score_attr\n",
    "\n",
    "    def prediction_rois(self, img, rois, ridx):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            sc_attr = self(img, rois, ridx)\n",
    "        score_attr = nn.functional.sigmoid(sc_attr)\n",
    "        attr = torch.where(sc_attr > 0.5, torch.tensor(1.0), torch.tensor(0.0))\n",
    "        return attr, score_attr\n",
    "\n",
    "    def calc_loss(\n",
    "        self,\n",
    "        attr,\n",
    "        labels,\n",
    "        gt_attr,\n",
    "    ):\n",
    "\n",
    "        bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        if (\n",
    "            len(attr[labels != 0]) == 0 or len(gt_attr[labels != 0]) == 0\n",
    "        ):  # gestisci il caso in cui non c'è bbox positivi\n",
    "            loss_attr = torch.tensor(0.0, requires_grad=True).to(labels.device)\n",
    "        else:\n",
    "            loss_attr = bce(attr[labels != 0], gt_attr[labels != 0])\n",
    "        return loss_attr\n",
    "\n",
    "\n",
    "class ObjectDetectionHead(nn.Module):\n",
    "    def __init__(self, num_classes=config[\"global\"][\"num_classes\"]):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.cls_score = nn.Linear(4096, self.num_classes + 1)\n",
    "        self.bbox = nn.Linear(4096, 4 * (self.num_classes + 1))\n",
    "\n",
    "        nn.init.normal_(self.cls_score.weight, mean=0, std=0.01)\n",
    "        nn.init.normal_(self.bbox.weight, mean=0, std=0.001)\n",
    "\n",
    "        nn.init.constant_(self.cls_score.bias, 0)\n",
    "        nn.init.constant_(self.bbox.bias, 0)\n",
    "\n",
    "    def forward(self, feat):\n",
    "        cls_score = self.cls_score(feat)\n",
    "        bbox = self.bbox(feat).view(-1, self.num_classes + 1, 4)\n",
    "        return cls_score, bbox\n",
    "\n",
    "\n",
    "class ObjectDetectionModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.alex = Backbone()\n",
    "        self.roi_module = ROI_Module()\n",
    "        self.obj_detect_head = ObjectDetectionHead(\n",
    "            num_classes=config[\"global\"][\"num_classes\"]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, rois, ridx):\n",
    "        out = self.alex(x)\n",
    "        out = self.roi_module(out, rois, ridx)\n",
    "        cls_score, bbox = self.obj_detect_head(out)\n",
    "        return cls_score, bbox\n",
    "\n",
    "    def prediction_img(self, img, rois, ridx):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            score, tbbox = self(img, rois, ridx)\n",
    "        _, _, heigth, width = img.shape\n",
    "        score = nn.functional.softmax(score, dim=-1)\n",
    "        max_score, cls_max_score = torch.max(score, dim=-1)\n",
    "\n",
    "        bboxs = regr_to_bbox(rois, tbbox, (heigth, width))\n",
    "\n",
    "        bboxs = bboxs[torch.arange(cls_max_score.shape[0]), cls_max_score]\n",
    "        return cls_max_score, max_score, bboxs\n",
    "\n",
    "    def calc_loss(\n",
    "        self,\n",
    "        probs,\n",
    "        bbox,\n",
    "        labels,\n",
    "        gt_bbox,\n",
    "    ):\n",
    "\n",
    "        cel = nn.CrossEntropyLoss()\n",
    "\n",
    "        sl1 = nn.SmoothL1Loss(reduction=\"none\")\n",
    "        loss_sc = cel(probs, labels)\n",
    "\n",
    "        mask = (labels != 0).bool()\n",
    "        t_u = bbox[torch.arange(bbox.shape[0]), labels]\n",
    "        loss_loc = (\n",
    "            torch.sum(torch.sum(sl1(t_u[mask], gt_bbox[mask]), dim=1), dim=0)\n",
    "            / labels.shape[0]\n",
    "        )\n",
    "\n",
    "        loss_sc = config[\"loss\"][\"lmb_cls\"] * loss_sc\n",
    "        loss_loc = config[\"loss\"][\"lmb_loc\"] * loss_loc\n",
    "        loss = loss_sc + loss_loc\n",
    "        return loss, loss_sc, loss_loc\n",
    "\n",
    "\n",
    "class CrossStitchBackbone(\n",
    "    nn.Module\n",
    "):  # one cross-stitch units after every pooling layer\n",
    "    def __init__(self, vgg_a, vgg_b):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        self.models_a = nn.ModuleList(\n",
    "            [nn.Sequential(*alex_a[i:j]) for i, j in [(0, 3), (3, 6), (6, 12)]]\n",
    "        )\n",
    "        self.models_b = nn.ModuleList(\n",
    "            [nn.Sequential(*alex_b[i:j]) for i, j in [(0, 3), (3, 6), (6, 12)]]\n",
    "        )\n",
    "        self.cross_stitch_units = nn.ModuleList([CrossStitchUnit() for _ in range(3)])\n",
    "        \"\"\"\n",
    "\n",
    "        # Identify the layers in VGG where pooling occurs\n",
    "        # VGG-16 structure: conv -> relu -> conv -> relu -> pool (repeat 5 times)\n",
    "        self.models_a = nn.ModuleList(\n",
    "            [\n",
    "                nn.Sequential(*vgg_a[i:j])\n",
    "                for i, j in [(0, 5), (5, 10), (10, 17), (17, 24), (24, 30)]\n",
    "            ]\n",
    "        )\n",
    "        self.models_b = nn.ModuleList(\n",
    "            [\n",
    "                nn.Sequential(*vgg_b[i:j])\n",
    "                for i, j in [(0, 5), (5, 10), (10, 17), (17, 24), (24, 30)]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Create CrossStitchUnits for each pooling layer\n",
    "        self.cross_stitch_units = nn.ModuleList([CrossStitchUnit() for _ in range(5)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_a, out_b = x, x\n",
    "        for model_a, model_b, cross_stitch in zip(\n",
    "            self.models_a, self.models_b, self.cross_stitch_units\n",
    "        ):\n",
    "            out_a, out_b = model_a(out_a), model_b(out_b)\n",
    "            out_a, out_b = cross_stitch(out_a, out_b)\n",
    "        return out_a, out_b\n",
    "\n",
    "\n",
    "class CrossStitchUnit(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.alfa_a = nn.Parameter(\n",
    "            torch.tensor(config[\"cross_stitch\"][\"alfa_a_init\"], dtype=torch.float32),\n",
    "            requires_grad=True,\n",
    "        )\n",
    "        self.alfa_b = nn.Parameter(\n",
    "            torch.tensor(config[\"cross_stitch\"][\"alfa_b_init\"], dtype=torch.float32),\n",
    "            requires_grad=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, xa, xb):\n",
    "        new_xa = self.alfa_a[0] * xa + self.alfa_a[1] * xb\n",
    "        new_xb = self.alfa_b[0] * xa + self.alfa_b[1] * xb\n",
    "        return new_xa, new_xb\n",
    "\n",
    "    def log_parameters(self):\n",
    "        # Loggare i valori di alfa_a e alfa_b su wandb\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"alfa_a_0\": self.alfa_a[0].item(),\n",
    "                \"alfa_a_1\": self.alfa_a[1].item(),\n",
    "                \"alfa_b_0\": self.alfa_b[0].item(),\n",
    "                \"alfa_b_1\": self.alfa_b[1].item(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "class CrossStitchNet(nn.Module):\n",
    "    def __init__(self, alex_a, alex_b):\n",
    "        super().__init__()\n",
    "        if alex_a is None or alex_b is None:\n",
    "            alex_a = Backbone()\n",
    "            alex_b = Backbone()\n",
    "        self.cross_stitch_net = CrossStitchBackbone(alex_a.features, alex_b.features)\n",
    "        self.roi_a = ROI_Module()\n",
    "        self.roi_b = ROI_Module()\n",
    "\n",
    "        self.model_obj_detect = ObjectDetectionHead(\n",
    "            num_classes=config[\"global\"][\"num_classes\"]\n",
    "        )\n",
    "        self.model_attribute = AttributePredictionHead(\n",
    "            num_attributes=config[\"global\"][\"num_attributes\"]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, rois, ridx):\n",
    "        out_a, out_b = self.cross_stitch_net(x)\n",
    "        out_a = self.roi_a(out_a, rois, ridx)\n",
    "        out_b = self.roi_b(out_b, rois, ridx)\n",
    "        cls_score, bbox = self.model_obj_detect(out_a)\n",
    "        attr_score = self.model_attribute(out_b)\n",
    "        return cls_score, bbox, attr_score  # cls_score, bbox, attr_score\n",
    "\n",
    "    def prediction_img(self, img, rois, ridx):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            score, tbbox, _ = self(img, rois, ridx)\n",
    "        _, _, heigth, width = img.shape\n",
    "        score = nn.functional.softmax(score, dim=-1)\n",
    "        max_score, cls_max_score = torch.max(score, dim=-1)\n",
    "\n",
    "        bboxs = regr_to_bbox(rois, tbbox, (heigth, width))\n",
    "\n",
    "        bboxs = bboxs[torch.arange(cls_max_score.shape[0]), cls_max_score]\n",
    "        # bboxs = self.unnormalize_bbox(bboxs)\n",
    "        return cls_max_score, max_score, bboxs\n",
    "\n",
    "    def prediction_rois(self, img, rois, ridx):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            _, _, sc_attr = self(img, rois, ridx)\n",
    "        score_attr = nn.functional.sigmoid(sc_attr)\n",
    "        attr = torch.where(\n",
    "            score_attr > 0.5,\n",
    "            torch.tensor(1.0, device=sc_attr.device),\n",
    "            torch.tensor(0.0, device=sc_attr.device),\n",
    "        )\n",
    "        return attr, score_attr\n",
    "\n",
    "    def calc_loss(\n",
    "        self,\n",
    "        probs,\n",
    "        bbox,\n",
    "        labels,\n",
    "        gt_bbox,\n",
    "        attr,\n",
    "        gt_attr,\n",
    "    ):\n",
    "\n",
    "        cel = nn.CrossEntropyLoss()\n",
    "        sl1 = nn.SmoothL1Loss(reduction=\"none\")\n",
    "        bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        loss_sc = cel(probs, labels)\n",
    "\n",
    "        mask = (labels != 0).bool()\n",
    "        t_u = bbox[torch.arange(bbox.shape[0]), labels]\n",
    "        loss_loc = (\n",
    "            torch.sum(torch.sum(sl1(t_u[mask], gt_bbox[mask]), dim=1), dim=0)\n",
    "            / labels.shape[0]\n",
    "        )\n",
    "        if (\n",
    "            len(attr[labels != 0]) == 0 or len(gt_attr[labels != 0]) == 0\n",
    "        ):  # gestiscri il caso in cui non c'è bbox positivi\n",
    "            loss_attr = torch.tensor(0.0, requires_grad=True).to(labels.device)\n",
    "        else:\n",
    "            loss_attr = bce(attr[labels != 0], gt_attr[labels != 0])\n",
    "\n",
    "        loss_sc = config[\"loss\"][\"lmb_cls\"] * loss_sc\n",
    "        loss_loc = config[\"loss\"][\"lmb_loc\"] * loss_loc\n",
    "        loss_attr = config[\"loss\"][\"lmb_attr\"] * loss_attr\n",
    "\n",
    "        loss = loss_sc + loss_loc\n",
    "\n",
    "        loss = loss_sc + loss_loc + loss_attr  # METTI LA COSTANTE DAVANTI A LOSS_ATTR\n",
    "\n",
    "        return loss, loss_sc, loss_loc, loss_attr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
