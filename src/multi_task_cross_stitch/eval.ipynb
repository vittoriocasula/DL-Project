{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model_to_eval = (\n",
    "    \"experiments/cross_stitch/2024-08-28_09-27-03/models/best_model_epoch_50.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data01/dl23vitcas/dl_project/src/multi_task_cross_stitch\n",
      "config/multi_task_cross_stitch.yaml\n",
      "experiments/cross_stitch/2024-08-28_09-27-03/models/best_model_epoch_50.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "print(os.getcwd())\n",
    "os.chdir(\"../../\")\n",
    "os.getcwd()\n",
    "\n",
    "sys.argv = [\n",
    "    \"view\",\n",
    "    \"--config\",\n",
    "    \"config/multi_task_cross_stitch.yaml\",\n",
    "    \"--model_path\",\n",
    "    path_model_to_eval,\n",
    "]\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--config\", type=str, required=True, help=\"Path to the config file\")\n",
    "parser.add_argument(\n",
    "    \"--model_path\", type=str, required=True, help=\"Path to the model pth\"\n",
    ")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(args.config)\n",
    "print(args.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from config_experiments import config, parse_args\n",
    "from utils import set_seed, set_device\n",
    "from dataloader import VOC08Attr\n",
    "import torchvision.transforms as transforms\n",
    "from model import ObjectDetectionModel, AttributePredictionModel, CrossStitchNet\n",
    "from metrics import (\n",
    "    compute_mAP_obj_detect,\n",
    "    compute_mAP_attr_predict,\n",
    ")\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_mAP_for_class(mAP, data_test):\n",
    "    print(f\"\\nmAP@0.50 (per class):\")\n",
    "    index = torch.arange(1, config[\"global\"][\"num_classes\"] + 1)\n",
    "\n",
    "    for i, value in zip(index, mAP[\"map_per_class\"].numpy()):\n",
    "        category = data_test.id2category.get(i.item())\n",
    "        mAP_category = value.item()\n",
    "\n",
    "        print(f\"\\tAP {category} : {(mAP_category):.2f}\")\n",
    "        wandb.config.update({f\"AP {category} \": mAP_category})\n",
    "\n",
    "    mAP50 = mAP[\"map_50\"].item()\n",
    "    print(f\"\\nmAP@0.50 : {mAP50:.2f}\")\n",
    "\n",
    "    wandb.config.update({\"mAP@0.50\": mAP50})\n",
    "\n",
    "\n",
    "def mAP_view_attributes(mAP, data_test):\n",
    "    print(mAP)\n",
    "    print(f\"\\nmAP@0.50 (per class):\")\n",
    "    for i, value in enumerate(mAP):\n",
    "        attribute = data_test.id2attribute[i + 1]\n",
    "        print(f\"AP {attribute}: {value:.2f}\")\n",
    "        wandb.config.update({f\"AP {attribute} \": value})\n",
    "    mAP = torch.mean(mAP)\n",
    "\n",
    "    print(f\"\\nmAP : {mAP:.2f}\")\n",
    "\n",
    "    wandb.config.update({\"mAP_attr@0.50\": mAP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = parse_args().model_path\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=config[\"transform\"][\"resize_values\"]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=config[\"transform\"][\"mean\"], std=config[\"transform\"][\"std\"]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "set_seed(config[\"global\"][\"seed\"])\n",
    "device = set_device(config[\"global\"][\"gpu_id\"])\n",
    "\n",
    "wandb.init(\n",
    "    group=\"cross_stitch\",\n",
    "    project=\"DL\",\n",
    "    config=config,\n",
    "    save_code=True,\n",
    "    mode=\"disabled\",\n",
    ")\n",
    "\n",
    "data_test = VOC08Attr(train=False, transform=transform_test)\n",
    "\n",
    "model = CrossStitchNet(\n",
    "    ObjectDetectionModel().to(device).backbone,\n",
    "    AttributePredictionModel().to(device).backbone,\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute mAP: 100%|██████████| 2227/2227 [14:50<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mAP@0.50 (per class):\n",
      "\tAP horse : 0.67\n",
      "\tAP person : 0.53\n",
      "\tAP bottle : 0.22\n",
      "\tAP dog : 0.65\n",
      "\tAP tvmonitor : 0.55\n",
      "\tAP car : 0.46\n",
      "\tAP aeroplane : 0.55\n",
      "\tAP bicycle : 0.49\n",
      "\tAP boat : 0.21\n",
      "\tAP chair : 0.23\n",
      "\tAP diningtable : 0.30\n",
      "\tAP pottedplant : 0.20\n",
      "\tAP train : 0.65\n",
      "\tAP cat : 0.68\n",
      "\tAP sofa : 0.26\n",
      "\tAP bird : 0.43\n",
      "\tAP sheep : 0.34\n",
      "\tAP motorbike : 0.62\n",
      "\tAP bus : 0.38\n",
      "\tAP cow : 0.35\n",
      "\n",
      "mAP@0.50 : 0.44\n"
     ]
    }
   ],
   "source": [
    "mAP = compute_mAP_obj_detect(data_test, model, device)\n",
    "view_mAP_for_class(mAP, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute mAP: 100%|██████████| 2227/2227 [04:30<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3297, 0.5857, 0.2522, 0.7700, 0.5375, 0.5488, 0.6866, 0.7294, 0.8696,\n",
      "        0.7974, 0.8580, 0.8198, 0.8077, 0.7852, 0.8060, 0.8071, 0.7717, 0.7034,\n",
      "        0.7959, 0.8125, 0.7211, 0.7932, 0.3445, 0.6528, 0.8050, 0.7136, 0.8089,\n",
      "        0.6562, 0.5499, 0.4371, 0.6107, 0.2699, 0.8157, 0.8212, 0.6169, 0.5841,\n",
      "        0.6762, 0.5488, 0.8131, 0.6569, 0.7509, 0.6977, 0.5179, 0.2413, 0.5604,\n",
      "        0.5781, 0.8639, 0.7095, 0.6523, 0.8648, 0.8982, 0.8097, 0.8494, 0.5089,\n",
      "        0.6373, 0.8485, 0.8903, 0.7636, 0.7854, 0.6745, 0.3488, 0.4545, 0.8617,\n",
      "        0.1109], device='cuda:0')\n",
      "\n",
      "mAP@0.50 (per class):\n",
      "AP 2D Boxy: 0.33\n",
      "AP 3D Boxy: 0.59\n",
      "AP Round: 0.25\n",
      "AP Vert Cyl: 0.77\n",
      "AP Horiz Cyl: 0.54\n",
      "AP Occluded: 0.55\n",
      "AP Tail: 0.69\n",
      "AP Beak: 0.73\n",
      "AP Head: 0.87\n",
      "AP Ear: 0.80\n",
      "AP Snout: 0.86\n",
      "AP Nose: 0.82\n",
      "AP Mouth: 0.81\n",
      "AP Hair: 0.79\n",
      "AP Face: 0.81\n",
      "AP Eye: 0.81\n",
      "AP Torso: 0.77\n",
      "AP Hand: 0.70\n",
      "AP Arm: 0.80\n",
      "AP Leg: 0.81\n",
      "AP Foot/Shoe: 0.72\n",
      "AP Wing: 0.79\n",
      "AP Propeller: 0.34\n",
      "AP Jet engine: 0.65\n",
      "AP Window: 0.80\n",
      "AP Row Wind: 0.71\n",
      "AP Wheel: 0.81\n",
      "AP Door: 0.66\n",
      "AP Headlight: 0.55\n",
      "AP Taillight: 0.44\n",
      "AP Side mirror: 0.61\n",
      "AP Exhaust: 0.27\n",
      "AP Pedal: 0.82\n",
      "AP Handlebars: 0.82\n",
      "AP Engine: 0.62\n",
      "AP Sail: 0.58\n",
      "AP Mast: 0.68\n",
      "AP Text: 0.55\n",
      "AP Label: 0.81\n",
      "AP Furn. Leg: 0.66\n",
      "AP Furn. Back: 0.75\n",
      "AP Furn. Seat: 0.70\n",
      "AP Furn. Arm: 0.52\n",
      "AP Horn: 0.24\n",
      "AP Rein: 0.56\n",
      "AP Saddle: 0.58\n",
      "AP Leaf: 0.86\n",
      "AP Flower: 0.71\n",
      "AP Stem/Trunk: 0.65\n",
      "AP Pot: 0.86\n",
      "AP Screen: 0.90\n",
      "AP Skin: 0.81\n",
      "AP Metal: 0.85\n",
      "AP Plastic: 0.51\n",
      "AP Wood: 0.64\n",
      "AP Cloth: 0.85\n",
      "AP Furry: 0.89\n",
      "AP Glass: 0.76\n",
      "AP Feather: 0.79\n",
      "AP Wool: 0.67\n",
      "AP Clear: 0.35\n",
      "AP Shiny: 0.45\n",
      "AP Vegetation: 0.86\n",
      "AP Leather: 0.11\n",
      "\n",
      "mAP : 0.67\n"
     ]
    }
   ],
   "source": [
    "mAP = compute_mAP_attr_predict(data_test, model, device)\n",
    "mAP_view_attributes(mAP, data_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
