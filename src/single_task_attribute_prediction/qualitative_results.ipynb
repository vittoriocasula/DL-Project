{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "print(os.getcwd())\n",
    "os.chdir(\"../../\")\n",
    "os.getcwd()\n",
    "\n",
    "sys.argv = [\"view\", \"--config\", \"config/single_task_attribute_prediction.yaml\"]\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--config\", type=str, required=True, help=\"Path to the config file\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(args.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments import config\n",
    "from torchvision.transforms import transforms\n",
    "from dataloader import VOC08Attr\n",
    "import matplotlib.pyplot as plt\n",
    "from model import AttributePredictionModel\n",
    "from utils import set_device\n",
    "import torch\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_val = transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(\n",
    "            size=config[\"transform\"][\"resize_values\"],\n",
    "            max_size=config[\"transform\"][\"max_size\"],\n",
    "        ),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=config[\"transform\"][\"mean\"], std=config[\"transform\"][\"std\"]\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../dl_project/experiments/attribute_prediction/2024-07-29_17-54-07/models/best_model_epoch_20.pth\"\n",
    "\n",
    "device = set_device(config[\"global\"][\"gpu_id\"])\n",
    "model = AttributePredictionModel().to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = VOC08Attr(train=False, transform=None)\n",
    "val_data_for_model = VOC08Attr(train=False, transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(idx):\n",
    "    img_transform, _, _, gt_bbox_transform, _, _ = val_data_for_model[idx]\n",
    "    img_transform = img_transform.unsqueeze(0).to(device)\n",
    "    gt_bbox_transform = gt_bbox_transform.to(device)\n",
    "\n",
    "    image, _, gt_class, gt_bbox, gt_attributes, _ = val_data[idx]\n",
    "\n",
    "    indices_batch = torch.zeros(gt_bbox_transform.shape[0], device=device).unsqueeze(-1)\n",
    "    pred_attr, pred_score_attr = model.prediction_rois(\n",
    "        img_transform, gt_bbox_transform, indices_batch\n",
    "    )\n",
    "    return (\n",
    "        image,\n",
    "        gt_bbox,\n",
    "        gt_class,\n",
    "        gt_attributes,\n",
    "        pred_attr.cpu(),\n",
    "        pred_score_attr.cpu(),\n",
    "    )\n",
    "\n",
    "\n",
    "def get_names_attributes(attributes):\n",
    "    indices = torch.nonzero(attributes == 1.0, as_tuple=True)[0] + 1\n",
    "    return [val_data.id2attribute[(idx)] for idx in indices.tolist()]\n",
    "\n",
    "\n",
    "def plot_inference(image, gt_bbox, gt_class, gt_attributes, pred_attr, pred_score_attr):\n",
    "    im = image\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(im)\n",
    "\n",
    "    for gt_el in gt_bbox:\n",
    "        x_min, y_min, x_max, y_max = gt_el\n",
    "\n",
    "        rect = patches.Rectangle(\n",
    "            (x_min, y_min),\n",
    "            x_max - x_min,\n",
    "            y_max - y_min,\n",
    "            linewidth=2,\n",
    "            edgecolor=\"g\",\n",
    "            facecolor=\"none\",\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    for i, (box, c, attr) in enumerate(zip(gt_bbox, gt_class, gt_attributes)):\n",
    "        print(\"\\nBOX:\\n\")\n",
    "        print(f\"{box.int()} \\t class: {c.item()} ({val_data.id2category[c.item()]})\")\n",
    "        print(f\"GT Attributes:  {get_names_attributes(attr)}\")\n",
    "        print(f\"NET Attributes:  {get_names_attributes(pred_attr[i])}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.randint(low=0, high=len(val_data), size=(1,))\n",
    "\n",
    "print(f\"IDX: {idx.item()}\\n\")\n",
    "image, gt_bbox, gt_class, gt_attributes, pred_attr, pred_score_attr = inference(idx=idx)\n",
    "plot_inference(image, gt_bbox, gt_class, gt_attributes, pred_attr, pred_score_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "def inference(idx):\n",
    "    img_transform, _, _, gt_bbox_transform, _, _ = val_data_for_model[idx]\n",
    "    img_transform = img_transform.unsqueeze(0).to(device)\n",
    "    gt_bbox_transform = gt_bbox_transform.to(device)\n",
    "\n",
    "    image, _, gt_class, gt_bbox, gt_attributes, _ = val_data[idx]\n",
    "\n",
    "    indices_batch = torch.zeros(gt_bbox_transform.shape[0], device=device).unsqueeze(-1)\n",
    "    pred_attr, pred_score_attr = model.prediction_rois(\n",
    "        img_transform, gt_bbox_transform, indices_batch\n",
    "    )\n",
    "    return (\n",
    "        image,\n",
    "        gt_bbox,\n",
    "        gt_class,\n",
    "        gt_attributes,\n",
    "        pred_attr.cpu(),\n",
    "        pred_score_attr.cpu(),\n",
    "    )\n",
    "\n",
    "\n",
    "def get_names_attributes(attributes):\n",
    "    indices = torch.nonzero(attributes == 1.0, as_tuple=True)[0] + 1\n",
    "    return [val_data.id2attribute[(idx)] for idx in indices.tolist()]\n",
    "\n",
    "\n",
    "def plot_multiple_inferences(num_images=8):\n",
    "    rows = 2\n",
    "    cols = 2\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(24, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(num_images):\n",
    "        idx = torch.randint(low=0, high=len(val_data), size=(1,)).item()\n",
    "        image, gt_bbox, _, gt_attributes, pred_attr, _ = inference(idx=idx)\n",
    "\n",
    "        ax = axes[i]\n",
    "        ax.imshow(image)\n",
    "\n",
    "        # Plot GT bounding boxes\n",
    "        for gt_el in gt_bbox:\n",
    "            x_min, y_min, x_max, y_max = gt_el\n",
    "            rect = patches.Rectangle(\n",
    "                (x_min, y_min),\n",
    "                x_max - x_min,\n",
    "                y_max - y_min,\n",
    "                linewidth=2,\n",
    "                edgecolor=\"g\",\n",
    "                facecolor=\"none\",\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "        # Prepare the attribute group for each bounding box\n",
    "        table_info = \"\"\n",
    "        for j, (gt_attr, net_attr) in enumerate(zip(gt_attributes, pred_attr)):\n",
    "            gt_attr_names = \", \".join(get_names_attributes(gt_attr))\n",
    "            net_attr_names = \", \".join(get_names_attributes(net_attr))\n",
    "            table_info += f\"Box {j+1}:\\nGT: {gt_attr_names}\\nNET: {net_attr_names}\\n\\n\"\n",
    "\n",
    "        # Handling cases where there are more GT attributes than predicted\n",
    "        for j in range(len(gt_attributes) - len(pred_attr)):\n",
    "            gt_attr_names = \", \".join(\n",
    "                get_names_attributes(gt_attributes[len(pred_attr) + j])\n",
    "            )\n",
    "            table_info += (\n",
    "                f\"Box {len(pred_attr) + j + 1}:\\nGT: {gt_attr_names}\\nNET: N/A\\n\\n\"\n",
    "            )\n",
    "\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title(f\"Image {idx}\", fontsize=16)\n",
    "\n",
    "        # Add text below the image using ax.text\n",
    "        ax.text(\n",
    "            0.5,\n",
    "            -0.2,\n",
    "            table_info,\n",
    "            fontsize=12,\n",
    "            ha=\"center\",\n",
    "            va=\"top\",\n",
    "            transform=ax.transAxes,\n",
    "            family=\"monospace\",\n",
    "        )\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Display 4 images in a 2x2 grid\n",
    "plot_multiple_inferences(num_images=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flower Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt = 1 , net = 1 --> green\n",
    "# gt = 1 , net = 0 --> red\n",
    "# gt = 0 , net = 1 --> blue\n",
    "\n",
    "\n",
    "def plot_inference_attribute(\n",
    "    image,\n",
    "    gt_bbox,\n",
    "    gt_class,\n",
    "    gt_attributes,\n",
    "    pred_attr,\n",
    "    pred_score_attr,\n",
    "    attr_idx,\n",
    "    image_idx,\n",
    "):\n",
    "\n",
    "    box_filter = []\n",
    "    colors = []\n",
    "    # filtrare le box che hanno attributo in gt o in net\n",
    "    for i_box, (gt_attr, net_attr) in enumerate(zip(gt_attributes, pred_attr)):\n",
    "        attr_gt_attr, attr_net_attr = gt_attr[attr_idx], net_attr[attr_idx]\n",
    "\n",
    "        if attr_gt_attr.item() == 1.0 and attr_net_attr.item() == 1.0:\n",
    "            colors.append(\"green\")\n",
    "            box_filter.append(gt_bbox[i_box])\n",
    "        if attr_gt_attr.item() == 1.0 and attr_net_attr.item() == 0.0:\n",
    "            colors.append(\"red\")\n",
    "            box_filter.append(gt_bbox[i_box])\n",
    "        if attr_gt_attr.item() == 0.0 and attr_net_attr.item() == 1.0:\n",
    "            colors.append(\"blue\")\n",
    "            box_filter.append(gt_bbox[i_box])\n",
    "\n",
    "    if not len(box_filter) == 0:\n",
    "        box_filter = torch.stack(box_filter)\n",
    "        im = image\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(im)\n",
    "\n",
    "        for i_col, gt_el in enumerate(box_filter):\n",
    "            x_min, y_min, x_max, y_max = gt_el\n",
    "\n",
    "            rect = patches.Rectangle(\n",
    "                (x_min, y_min),\n",
    "                x_max - x_min,\n",
    "                y_max - y_min,\n",
    "                linewidth=2,\n",
    "                edgecolor=colors[i_col],\n",
    "                facecolor=\"none\",\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "        # print(f\"IDX:{image_idx}\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_idx = 47\n",
    "for idx in range(len(val_data)):\n",
    "    image, gt_bbox, gt_class, gt_attributes, pred_attr, pred_score_attr = inference(\n",
    "        idx=idx\n",
    "    )\n",
    "\n",
    "    plot_inference_attribute(\n",
    "        image,\n",
    "        gt_bbox,\n",
    "        gt_class,\n",
    "        gt_attributes,\n",
    "        pred_attr,\n",
    "        pred_score_attr,\n",
    "        attr_idx,\n",
    "        idx,\n",
    "    )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import torch\n",
    "\n",
    "\n",
    "def plot_inference_attribute(\n",
    "    image,\n",
    "    gt_bbox,\n",
    "    gt_class,\n",
    "    gt_attributes,\n",
    "    pred_attr,\n",
    "    pred_score_attr,\n",
    "    attr_idx,\n",
    "    ax,\n",
    "):\n",
    "    box_filter = []\n",
    "    colors = []\n",
    "    ax.axis(\"off\")\n",
    "    # Filter boxes based on the specified attribute\n",
    "    for i_box, (gt_attr, net_attr) in enumerate(zip(gt_attributes, pred_attr)):\n",
    "        attr_gt_attr, attr_net_attr = gt_attr[attr_idx], net_attr[attr_idx]\n",
    "\n",
    "        if attr_gt_attr.item() == 1.0 and attr_net_attr.item() == 1.0:\n",
    "            colors.append(\"green\")\n",
    "            box_filter.append(gt_bbox[i_box])\n",
    "        elif attr_gt_attr.item() == 1.0 and attr_net_attr.item() == 0.0:\n",
    "            colors.append(\"red\")\n",
    "            box_filter.append(gt_bbox[i_box])\n",
    "        elif attr_gt_attr.item() == 0.0 and attr_net_attr.item() == 1.0:\n",
    "            colors.append(\"blue\")\n",
    "            box_filter.append(gt_bbox[i_box])\n",
    "\n",
    "    if box_filter:\n",
    "        box_filter = torch.stack(box_filter)\n",
    "        ax.imshow(image)\n",
    "\n",
    "        for i_col, gt_el in enumerate(box_filter):\n",
    "            x_min, y_min, x_max, y_max = gt_el\n",
    "\n",
    "            rect = patches.Rectangle(\n",
    "                (x_min, y_min),\n",
    "                x_max - x_min,\n",
    "                y_max - y_min,\n",
    "                linewidth=2,\n",
    "                edgecolor=colors[i_col],\n",
    "                facecolor=\"none\",\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "\n",
    "# Specific indices of images to display\n",
    "specific_indices = [691, 140, 1660, 834, 855, 1036, 1037, 96]\n",
    "specific_indices = [691, 1660, 855, 1037, 140, 834, 1036, 96]\n",
    "\n",
    "\n",
    "# Prepare figure with 2 rows and 4 columns\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "attr_idx = 47\n",
    "for plot_idx, idx in enumerate(specific_indices):\n",
    "    # Retrieve data for the specific index\n",
    "    image, gt_bbox, gt_class, gt_attributes, pred_attr, pred_score_attr = inference(\n",
    "        idx=idx\n",
    "    )\n",
    "\n",
    "    # Plot the image and attributes on the corresponding subplot\n",
    "    plot_inference_attribute(\n",
    "        image,\n",
    "        gt_bbox,\n",
    "        gt_class,\n",
    "        gt_attributes,\n",
    "        pred_attr,\n",
    "        pred_score_attr,\n",
    "        attr_idx,\n",
    "        axes[plot_idx],\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
