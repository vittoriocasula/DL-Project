{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model_to_eval = \"experiments/attribute_prediction/2024-09-01_11-03-41/models/model_epoch_10.pth\"  # TODO CHANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data01/dl23vitcas/dl_project/src/single_task_attribute_prediction\n",
      "config/single_task_attribute_prediction.yaml\n",
      "experiments/attribute_prediction/2024-09-01_11-03-41/models/model_epoch_10.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "print(os.getcwd())\n",
    "os.chdir(\"../../\")\n",
    "os.getcwd()\n",
    "\n",
    "sys.argv = [\n",
    "    \"view\",\n",
    "    \"--config\",\n",
    "    \"config/single_task_attribute_prediction.yaml\",\n",
    "    \"--model_path\",\n",
    "    path_model_to_eval,\n",
    "]\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--config\", type=str, required=True, help=\"Path to the config file\")\n",
    "parser.add_argument(\n",
    "    \"--model_path\", type=str, required=True, help=\"Path to the model pth\"\n",
    ")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(args.config)\n",
    "print(args.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from config_experiments import config, parse_args\n",
    "from utils import set_seed, set_device\n",
    "from dataloader import VOC08Attr\n",
    "import torchvision.transforms as transforms\n",
    "from model import AttributePredictionModel\n",
    "from metrics import compute_mAP\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mAP_view_attributes(mAP, data_test):\n",
    "    print(mAP)\n",
    "    print(f\"\\nmAP@0.50 (per class):\")\n",
    "    for i, value in enumerate(mAP):\n",
    "        attribute = data_test.id2attribute[i + 1]\n",
    "        print(f\"AP {attribute}: {value:.2f}\")\n",
    "        wandb.config.update({f\"AP {attribute} \": value})\n",
    "    mAP = torch.mean(mAP)\n",
    "\n",
    "    print(f\"\\nmAP : {mAP:.2f}\")\n",
    "\n",
    "    wandb.config.update({\"mAP_attr@0.50\": mAP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = parse_args().model_path\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=config[\"transform\"][\"resize_values\"]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=config[\"transform\"][\"mean\"], std=config[\"transform\"][\"std\"]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "set_seed(config[\"global\"][\"seed\"])\n",
    "device = set_device(config[\"global\"][\"gpu_id\"])\n",
    "\n",
    "\n",
    "wandb.init(\n",
    "    group=\"attribute prediction\",\n",
    "    project=\"DL\",\n",
    "    config=config,\n",
    "    save_code=True,\n",
    "    mode=\"disabled\",\n",
    ")\n",
    "\n",
    "data_test = VOC08Attr(train=False, transform=transform_test)\n",
    "model = AttributePredictionModel().to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute mAP: 100%|██████████| 2227/2227 [03:30<00:00, 10.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3495, 0.5960, 0.1510, 0.7580, 0.6092, 0.5733, 0.6805, 0.7405, 0.8661,\n",
      "        0.7842, 0.8488, 0.8112, 0.7947, 0.7743, 0.8074, 0.8038, 0.7954, 0.7254,\n",
      "        0.7974, 0.8220, 0.7146, 0.8006, 0.2078, 0.6808, 0.8141, 0.6867, 0.8093,\n",
      "        0.6553, 0.5226, 0.4353, 0.5990, 0.2827, 0.7758, 0.8016, 0.5856, 0.6182,\n",
      "        0.6844, 0.5850, 0.8121, 0.6354, 0.6925, 0.6399, 0.5136, 0.1927, 0.5533,\n",
      "        0.5062, 0.8338, 0.3841, 0.5673, 0.8203, 0.8668, 0.8077, 0.8484, 0.4790,\n",
      "        0.6108, 0.8510, 0.8767, 0.7066, 0.8052, 0.6275, 0.3485, 0.5000, 0.8333,\n",
      "        0.1306], device='cuda:0')\n",
      "\n",
      "mAP@0.50 (per class):\n",
      "AP 2D Boxy: 0.35\n",
      "AP 3D Boxy: 0.60\n",
      "AP Round: 0.15\n",
      "AP Vert Cyl: 0.76\n",
      "AP Horiz Cyl: 0.61\n",
      "AP Occluded: 0.57\n",
      "AP Tail: 0.68\n",
      "AP Beak: 0.74\n",
      "AP Head: 0.87\n",
      "AP Ear: 0.78\n",
      "AP Snout: 0.85\n",
      "AP Nose: 0.81\n",
      "AP Mouth: 0.79\n",
      "AP Hair: 0.77\n",
      "AP Face: 0.81\n",
      "AP Eye: 0.80\n",
      "AP Torso: 0.80\n",
      "AP Hand: 0.73\n",
      "AP Arm: 0.80\n",
      "AP Leg: 0.82\n",
      "AP Foot/Shoe: 0.71\n",
      "AP Wing: 0.80\n",
      "AP Propeller: 0.21\n",
      "AP Jet engine: 0.68\n",
      "AP Window: 0.81\n",
      "AP Row Wind: 0.69\n",
      "AP Wheel: 0.81\n",
      "AP Door: 0.66\n",
      "AP Headlight: 0.52\n",
      "AP Taillight: 0.44\n",
      "AP Side mirror: 0.60\n",
      "AP Exhaust: 0.28\n",
      "AP Pedal: 0.78\n",
      "AP Handlebars: 0.80\n",
      "AP Engine: 0.59\n",
      "AP Sail: 0.62\n",
      "AP Mast: 0.68\n",
      "AP Text: 0.59\n",
      "AP Label: 0.81\n",
      "AP Furn. Leg: 0.64\n",
      "AP Furn. Back: 0.69\n",
      "AP Furn. Seat: 0.64\n",
      "AP Furn. Arm: 0.51\n",
      "AP Horn: 0.19\n",
      "AP Rein: 0.55\n",
      "AP Saddle: 0.51\n",
      "AP Leaf: 0.83\n",
      "AP Flower: 0.38\n",
      "AP Stem/Trunk: 0.57\n",
      "AP Pot: 0.82\n",
      "AP Screen: 0.87\n",
      "AP Skin: 0.81\n",
      "AP Metal: 0.85\n",
      "AP Plastic: 0.48\n",
      "AP Wood: 0.61\n",
      "AP Cloth: 0.85\n",
      "AP Furry: 0.88\n",
      "AP Glass: 0.71\n",
      "AP Feather: 0.81\n",
      "AP Wool: 0.63\n",
      "AP Clear: 0.35\n",
      "AP Shiny: 0.50\n",
      "AP Vegetation: 0.83\n",
      "AP Leather: 0.13\n",
      "\n",
      "mAP : 0.65\n"
     ]
    }
   ],
   "source": [
    "mAP = compute_mAP(data_test, model, device)\n",
    "mAP_view_attributes(mAP, data_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
