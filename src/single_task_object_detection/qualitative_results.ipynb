{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "print(os.getcwd())\n",
    "os.chdir(\"../../\")\n",
    "os.getcwd()\n",
    "\n",
    "sys.argv = [\"view\", \"--config\", \"config/single_task_object_detection.yaml\"]\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--config\", type=str, required=True, help=\"Path to the config file\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(args.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments import config\n",
    "from torchvision.transforms import transforms\n",
    "from dataloader import VOC08Attr\n",
    "import matplotlib.pyplot as plt\n",
    "from model import ObjectDetectionModel\n",
    "from utils import set_device\n",
    "import torch\n",
    "from bbox_transform import resize_bounding_boxes, apply_nms\n",
    "import matplotlib.patches as patches\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_val = transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(\n",
    "            size=config[\"transform\"][\"resize_values\"],\n",
    "            max_size=config[\"transform\"][\"max_size\"],\n",
    "        ),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=config[\"transform\"][\"mean\"], std=config[\"transform\"][\"std\"]\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = \"../dl_project/experiments/object_detection/2024-07-25_10-51-08/models/best_model_epoch_95.pth\"\n",
    "model_path = \"../dl_project/experiments/object_detection/2024-07-28_19-23-43/models/model_epoch_75.pth\"\n",
    "\n",
    "device = set_device(config[\"global\"][\"gpu_id\"])\n",
    "model = ObjectDetectionModel().to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = VOC08Attr(train=False, transform=None)\n",
    "val_data_for_model = VOC08Attr(train=False, transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(idx):\n",
    "    img_transform, img_size_orig_transform, _, _, _, ss_rois_transform = (\n",
    "        val_data_for_model[idx]\n",
    "    )\n",
    "    image, img_size_orig, gt_class, gt_bbox, gt_attributes, ss_rois = val_data[idx]\n",
    "    img_transform = img_transform.unsqueeze(0).to(device)\n",
    "    ss_rois_transform = ss_rois_transform.to(device)\n",
    "\n",
    "    indices_batch = torch.zeros(ss_rois_transform.shape[0], device=device).unsqueeze(-1)\n",
    "\n",
    "    cls_max_score_net, max_score_net, bboxs_net = model.prediction_img(\n",
    "        img_transform, ss_rois_transform, indices_batch\n",
    "    )\n",
    "\n",
    "    bboxs_net = resize_bounding_boxes(\n",
    "        bboxs_net,\n",
    "        orig_size=(img_transform.shape[3], img_transform.shape[2]),\n",
    "        new_size=img_size_orig_transform,\n",
    "    )\n",
    "\n",
    "    pred_bbox, pred_class, pred_score = apply_nms(\n",
    "        cls_max_score_net, max_score_net, bboxs_net\n",
    "    )\n",
    "    pred_bbox, pred_class, pred_score = (\n",
    "        pred_bbox.cpu(),\n",
    "        pred_class.cpu(),\n",
    "        pred_score.cpu(),\n",
    "    )\n",
    "    return image, gt_bbox, gt_class, pred_bbox, pred_class, pred_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_inference(image, gt_bbox, gt_class, pred_bbox, pred_class, pred_score):\n",
    "    im = image\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(im)\n",
    "\n",
    "    for gt_el in gt_bbox:\n",
    "        x_min, y_min, x_max, y_max = gt_el\n",
    "\n",
    "        rect = patches.Rectangle(\n",
    "            (x_min, y_min),\n",
    "            x_max - x_min,\n",
    "            y_max - y_min,\n",
    "            linewidth=2,\n",
    "            edgecolor=\"g\",\n",
    "            facecolor=\"none\",\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    for pred_el in pred_bbox:\n",
    "        x_min, y_min, x_max, y_max = pred_el\n",
    "\n",
    "        rect = patches.Rectangle(\n",
    "            (x_min, y_min),\n",
    "            x_max - x_min,\n",
    "            y_max - y_min,\n",
    "            linewidth=1,\n",
    "            edgecolor=\"r\",\n",
    "            facecolor=\"none\",\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    print(\"NET\")\n",
    "    for box, c, score in zip(pred_bbox, pred_class, pred_score):\n",
    "        print(\n",
    "            f\"{box.int()} \\t class: {c.item()} ({val_data.id2category[c.item()]}) \\tscore: {score.item():.3f}\"\n",
    "        )\n",
    "\n",
    "    print(\"\\nGT\")\n",
    "\n",
    "    for box, c in zip(gt_bbox, gt_class):\n",
    "        print(f\"{box.int()} \\t class: {c.item()} ({val_data.id2category[c.item()]})\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.randint(low=0, high=len(val_data), size=(1,))\n",
    "\n",
    "print(f\"IDX: {idx.item()}\\n\")\n",
    "image, gt_bbox, gt_class, pred_bbox, pred_class, pred_score = inference(idx=idx)\n",
    "plot_inference(image, gt_bbox, gt_class, pred_bbox, pred_class, pred_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "def inference(idx):\n",
    "    img_transform, img_size_orig_transform, _, _, _, ss_rois_transform = (\n",
    "        val_data_for_model[idx]\n",
    "    )\n",
    "    image, img_size_orig, gt_class, gt_bbox, gt_attributes, ss_rois = val_data[idx]\n",
    "    img_transform = img_transform.unsqueeze(0).to(device)\n",
    "    ss_rois_transform = ss_rois_transform.to(device)\n",
    "\n",
    "    indices_batch = torch.zeros(ss_rois_transform.shape[0], device=device).unsqueeze(-1)\n",
    "\n",
    "    cls_max_score_net, max_score_net, bboxs_net = model.prediction_img(\n",
    "        img_transform, ss_rois_transform, indices_batch\n",
    "    )\n",
    "\n",
    "    bboxs_net = resize_bounding_boxes(\n",
    "        bboxs_net,\n",
    "        orig_size=(img_transform.shape[3], img_transform.shape[2]),\n",
    "        new_size=img_size_orig_transform,\n",
    "    )\n",
    "\n",
    "    pred_bbox, pred_class, pred_score = apply_nms(\n",
    "        cls_max_score_net, max_score_net, bboxs_net\n",
    "    )\n",
    "    pred_bbox, pred_class, pred_score = (\n",
    "        pred_bbox.cpu(),\n",
    "        pred_class.cpu(),\n",
    "        pred_score.cpu(),\n",
    "    )\n",
    "    return image, gt_bbox, gt_class, pred_bbox, pred_class, pred_score\n",
    "\n",
    "\n",
    "def plot_inference_multiple(images_data, indices):\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(20, 10))  # 2 righe, 4 colonne\n",
    "    axs = axs.ravel()  # per iterare facilmente sugli assi\n",
    "\n",
    "    for i, (image, gt_bbox, gt_class, pred_bbox, pred_class, pred_score) in enumerate(\n",
    "        images_data\n",
    "    ):\n",
    "        ax = axs[i]\n",
    "        ax.imshow(image)\n",
    "\n",
    "        for gt_el in gt_bbox:\n",
    "            x_min, y_min, x_max, y_max = gt_el\n",
    "            rect = patches.Rectangle(\n",
    "                (x_min, y_min),\n",
    "                x_max - x_min,\n",
    "                y_max - y_min,\n",
    "                linewidth=2,\n",
    "                edgecolor=\"g\",\n",
    "                facecolor=\"none\",\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "        for pred_el in pred_bbox:\n",
    "            x_min, y_min, x_max, y_max = pred_el\n",
    "            rect = patches.Rectangle(\n",
    "                (x_min, y_min),\n",
    "                x_max - x_min,\n",
    "                y_max - y_min,\n",
    "                linewidth=1,\n",
    "                edgecolor=\"r\",\n",
    "                facecolor=\"none\",\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "        ax.set_title(f\"Image {indices[i]}\")\n",
    "        ax.axis(\"off\")  # Nascondi assi\n",
    "\n",
    "        \"\"\"\n",
    "        print(f\"Image {i + 1} - NET\")\n",
    "        for box, c, score in zip(pred_bbox, pred_class, pred_score):\n",
    "            print(\n",
    "                f\"{box.int()} \\t class: {c.item()} ({val_data.id2category[c.item()]}) \\tscore: {score.item():.3f}\"\n",
    "            )\n",
    "\n",
    "        print(f\"\\nImage {i + 1} - GT\")\n",
    "        for box, c in zip(gt_bbox, gt_class):\n",
    "            print(\n",
    "                f\"{box.int()} \\t class: {c.item()} ({val_data.id2category[c.item()]})\"\n",
    "            )\n",
    "        \"\"\"\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Seleziona 8 indici casuali dal dataset di validazione\n",
    "indices = torch.randint(low=0, high=len(val_data), size=(8,))\n",
    "print(indices)\n",
    "\n",
    "# Esegui inferenza e colleziona i risultati\n",
    "images_data = [inference(idx.item()) for idx in indices]\n",
    "\n",
    "# Plot dei risultati\n",
    "plot_inference_multiple(images_data, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific Examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziona 8 indici casuali dal dataset di validazione\n",
    "indices_best_examples = [260, 805, 1455, 293]\n",
    "indices_worse_examples = [1376, 1198, 1637, 2013]\n",
    "\n",
    "\n",
    "indices = torch.tensor(indices_best_examples + indices_worse_examples)\n",
    "print(indices)\n",
    "\n",
    "# Esegui inferenza e colleziona i risultati\n",
    "images_data = [inference(idx.item()) for idx in indices]\n",
    "\n",
    "# Plot dei risultati\n",
    "plot_inference_multiple(images_data, indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
