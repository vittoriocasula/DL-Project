{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model_to_eval = \"experiments/object_detection/2024-09-01_11-01-16/models/model_epoch_10.pth\"  # TODO CHANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data01/dl23vitcas/dl_project/src/single_task_object_detection\n",
      "config/single_task_object_detection.yaml\n",
      "experiments/object_detection/2024-09-01_11-01-16/models/model_epoch_10.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "print(os.getcwd())\n",
    "os.chdir(\"../../\")\n",
    "os.getcwd()\n",
    "\n",
    "sys.argv = [\n",
    "    \"view\",\n",
    "    \"--config\",\n",
    "    \"config/single_task_object_detection.yaml\",\n",
    "    \"--model_path\",\n",
    "    path_model_to_eval,\n",
    "]\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--config\", type=str, required=True, help=\"Path to the config file\")\n",
    "parser.add_argument(\n",
    "    \"--model_path\", type=str, required=True, help=\"Path to the model pth\"\n",
    ")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(args.config)\n",
    "print(args.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from config_experiments import config, parse_args\n",
    "from utils import set_seed, set_device\n",
    "from dataloader import VOC08Attr\n",
    "import torchvision.transforms as transforms\n",
    "from model import ObjectDetectionModel\n",
    "from metrics import compute_mAP\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_mAP_for_class(mAP, data_test):\n",
    "    print(f\"\\nmAP@0.50 (per class):\")\n",
    "    index = torch.arange(1, config[\"global\"][\"num_classes\"] + 1)\n",
    "\n",
    "    for i, value in zip(index, mAP[\"map_per_class\"].numpy()):\n",
    "        category = data_test.id2category.get(i.item())\n",
    "        mAP_category = value.item()\n",
    "\n",
    "        print(f\"\\tAP {category} : {(mAP_category):.2f}\")\n",
    "        wandb.config.update({f\"AP {category} \": mAP_category})\n",
    "\n",
    "    mAP50 = mAP[\"map_50\"].item()\n",
    "    print(f\"\\nmAP@0.50 : {mAP50:.2f}\")\n",
    "\n",
    "    wandb.config.update({\"mAP@0.50\": mAP50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = parse_args().model_path\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=config[\"transform\"][\"resize_values\"]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=config[\"transform\"][\"mean\"], std=config[\"transform\"][\"std\"]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "set_seed(config[\"global\"][\"seed\"])\n",
    "device = set_device(config[\"global\"][\"gpu_id\"])\n",
    "\n",
    "\n",
    "wandb.init(\n",
    "    group=\"object_detection\",\n",
    "    project=\"DL\",\n",
    "    config=config,\n",
    "    save_code=True,\n",
    "    mode=\"disabled\",\n",
    ")\n",
    "\n",
    "data_test = VOC08Attr(train=False, transform=transform_test)\n",
    "model = ObjectDetectionModel().to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute mAP: 100%|██████████| 2227/2227 [07:26<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mAP@0.50 (per class):\n",
      "\tAP horse : 0.55\n",
      "\tAP person : 0.48\n",
      "\tAP bottle : 0.15\n",
      "\tAP dog : 0.38\n",
      "\tAP tvmonitor : 0.54\n",
      "\tAP car : 0.36\n",
      "\tAP aeroplane : 0.35\n",
      "\tAP bicycle : 0.47\n",
      "\tAP boat : 0.15\n",
      "\tAP chair : 0.18\n",
      "\tAP diningtable : 0.30\n",
      "\tAP pottedplant : 0.20\n",
      "\tAP train : 0.55\n",
      "\tAP cat : 0.24\n",
      "\tAP sofa : 0.32\n",
      "\tAP bird : 0.30\n",
      "\tAP sheep : 0.19\n",
      "\tAP motorbike : 0.18\n",
      "\tAP bus : 0.30\n",
      "\tAP cow : 0.34\n",
      "\n",
      "mAP@0.50 : 0.33\n"
     ]
    }
   ],
   "source": [
    "mAP = compute_mAP(data_test, model, device)\n",
    "view_mAP_for_class(mAP, data_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
