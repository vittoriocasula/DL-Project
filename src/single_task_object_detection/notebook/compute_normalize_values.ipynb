{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir(\"../../\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "sys.argv = [\"view\", \"--config\", \"config/single_task_object_detection.yaml\"]\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--config\", type=str, required=True, help=\"Path to the config file\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(args.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import VOC08Attr\n",
    "from torchvision.transforms import transforms\n",
    "from config_experiments import config\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=600, max_size=1000),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=config[\"transform\"][\"mean\"], std=config[\"transform\"][\"std\"]\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = VOC08Attr(train=True, transform=transform_train)\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=config[\"preprocessing\"][\"n_images\"],\n",
    "    collate_fn=train_data.collate_fn,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def show(imgs):\n",
    "    plt.rcParams[\"savefig.bbox\"] = \"tight\"\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)  # (H, W)\n",
    "        axs[0, i].imshow(np.asarray(img))  # (W, H, 3)\n",
    "        # axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[]) # uncomment to remove axis in plot\n",
    "\n",
    "\n",
    "def show_bbox_with_transform(image, box, mean, std, labels=None, color=\"white\"):\n",
    "    image = np.array(image)\n",
    "    for channel in range(3):\n",
    "        image[channel] = image[channel] * std[channel] + mean[channel]\n",
    "    image = np.clip(image, 0, 1)\n",
    "    image = (image * 255).astype(np.uint8)\n",
    "    image = torch.from_numpy(image)\n",
    "    show(draw_bounding_boxes(image, box, colors=color, labels=labels, width=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (batch_images, rois, classes, offsets, attrs, indices_batch) in enumerate(\n",
    "    train_dataloader\n",
    "):\n",
    "    # show(batch_images[0])\n",
    "    # show(batch_images[1])\n",
    "    # print(rois.shape)\n",
    "    print(rois[indices_batch.squeeze(-1) == 0])\n",
    "    show_bbox_with_transform(\n",
    "        batch_images[0],\n",
    "        rois[indices_batch.squeeze(-1) == 0],\n",
    "        [0.485, 0.456, 0.406],\n",
    "        [0.229, 0.224, 0.225],\n",
    "        labels=None,\n",
    "        color=\"white\",\n",
    "    )\n",
    "    print(rois[indices_batch.squeeze(-1) == 1])\n",
    "    show_bbox_with_transform(\n",
    "        batch_images[1],\n",
    "        rois[indices_batch.squeeze(-1) == 1],\n",
    "        [0.485, 0.456, 0.406],\n",
    "        [0.229, 0.224, 0.225],\n",
    "        labels=None,\n",
    "        color=\"black\",\n",
    "    )\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalize_values_target_class(data_loader):\n",
    "    offsets_by_class = {i: [] for i in range(1, config[\"global\"][\"num_classes\"] + 1)}\n",
    "    for i, (image, train_roi, train_cls, train_offset, _, indices_batch) in enumerate(\n",
    "        data_loader\n",
    "    ):\n",
    "        for cls, offset in zip(train_cls, train_offset):\n",
    "            if cls.item() in offsets_by_class and cls.item() != 0:\n",
    "                offsets_by_class[cls.item()].append(offset)\n",
    "\n",
    "    mean_std_by_class = {}\n",
    "    for cls, offsets in offsets_by_class.items():\n",
    "        offsets_tensor = torch.stack(offsets)\n",
    "        mean = torch.mean(offsets_tensor, dim=0)\n",
    "        std = torch.std(offsets_tensor, dim=0)\n",
    "        mean_std_by_class[cls] = {\n",
    "            \"mean\": mean.tolist(),\n",
    "            \"std\": std.tolist(),\n",
    "        }\n",
    "\n",
    "    return mean_std_by_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std_by_class = get_normalize_values_target_class(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\n",
    "    os.getcwd()\n",
    "    + \"/src/single_task_object_detection/\"\n",
    "    + \"target_mean_std_by_class.yaml\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "\n",
    "    json.dump(mean_std_by_class, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\n",
    "    os.getcwd()\n",
    "    + \"/src/single_task_object_detection/\"\n",
    "    + \"target_mean_std_by_class.yaml\",\n",
    "    \"r\",\n",
    ") as f:\n",
    "    mean_std_by_class = yaml.safe_load(f)\n",
    "\n",
    "    print(mean_std_by_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
